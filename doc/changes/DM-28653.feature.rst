* Added bps htcondor job setting that should put jobs that
  get the signal 7 when exceeding memory on hold.  Held
  message will say: "Job raised a signal 7.  Usually means
  job has gone over memory limit."  Until bps has the
  automatic memory exceeded retries, you can restart these
  the same way as with jobs that htcondor held for exceeding
  memory limits (condor_qedit and condor_release).

* Too many files were being written to single directories in
  job/<label>.  There is now a template for it defined in yaml:
  subDirTemplate: "{label}/{tract}/{patch}/{visit.day_obs}/{exposure.day_obs}/{band}/{subfilter}/{physical_filter}/{visit}/{exposure}"

  To revert back to previous behavior, in your submit yaml set:
  subDirTemplate: "{label}"

* bps now has defaults so submit yamls should be a lot simpler and
  require less changes when bps or pipetask changes.  For default
  values see ${CTRL_BPS_DIR}/python/lsst/ctrl/bps/etc/bps_defaults.yaml.
  See ${CTRL_BPS_DIR}/doc/lsst.ctrl.bps/pipelines_check.yaml for
  an example of much simpler submit yaml.

  Values in bps_defaults.yaml are overridden by values in submit
  yaml (be careful of scoping rules e.g., values in a pipetask
  section override the global setting).

  STRONGLY recommend removing (commenting out) settings in the
  submit yaml that are set in the default yaml (i.e., the settings
  that are same across runs across repos, ...)

  It would be helpful to know in what cases submit yamls have to
  override default settings, in particular the command lines.

* With the above defaults one can more easily append options to the
  pipetask command lines as variables in submit yaml:

  * extraQgraphOptions: Adds given string to end of command line for
    creating QuantumGraph (e.g., for specifying a task wit -t)

  * extraInitOptions: Adds given string to end of pipetaskInit
    command line

  * extraRunQuantumOptions: Adds given string to end of the pipetask
    command line for running a Quantum (e.g., "--no-versions")

  These can also be specified on the command line (see `bps submit --help`).
  * --extra-qgraph-options TEXT
  * --extra-init-options TEXT
  * --extra-run-quantum-options TEXT

  Settings on command line override values set in submit yaml.

  The default commands no longer include "--no-versions" or saving
  a dot version of the QuantumGraph.  Use the appropriate new variable
  or command-line option to add those back.

* Can specify some pipetask options on command line (see `bps submit --help`):
  * -b, --butler-config TEXT
  * -i, --input COLLECTION ...
  * -o, --output COLL
  * --output-run COLL
  * -d, --data-query QUERY
  * -p, --pipeline FILE
  * -g, --qgraph TEXT

  Settings on command line override values set in submit yaml.

* bps now saves yaml in run's submit directory.  One is
  just a copy of the submit yaml (uses original filename).  And
  one is a dump of the config after combining command-line options,
  defaults and submit yaml (<run>_config.yaml).

* If pipetask starts reporting errors about database connections
  (e.g., remaining connection slots are reserved for non-replication
  superuser connections) ask on #dm-middleware-support about
  using execution butler in bps.  This greatly reduces the number of
  connections to the central database per run.  It is not yet the default
  behavior of bps, but one can modify the submit yaml to use it.  See
  ${CTRL_BPS_DIR}/doc/lsst.ctrl.bps/pipelines_check_execution_butler.yaml

The major differences visible to users are:

* bps report shows new job called mergeExecutionButler in detailed view.
  This is what saves the run info into the central butler repository.
  As with any job, it can succeed or fail.  Different from other jobs, it
  will execute at the end of a run regardless of whether a job failed or
  not.  It will even execute if the run is cancelled unless the cancellation
  is while the merge is running.  Its output will go where other jobs go (at
  NCSA in jobs/mergeExecutionButler directory).

* See new files in submit directory:

  * EXEC_REPO-<run>:  Execution butler (yaml + initial sqlite file)
  * execution_butler_creation.out: output of command to create execution butler
  * final_job.bash:  Script that is executed to do the merging of the run info into the central repo.
  * final_post_mergeExecutionButler.out: An internal file for debugging incorrect reporting of final run status.

